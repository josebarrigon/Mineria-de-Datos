{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d6e5fb4899a86812cf0beff363aaab4e",
     "grade": false,
     "grade_id": "cell-a7f1dee03483c56a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Práctica de validación/selección de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c778ae8401287bf4ae7b337f8d2ef282",
     "grade": false,
     "grade_id": "cell-c1d42050f5d06517",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "- [Método Hold-out](#Método-Hold-out)\n",
    "- [Método validación cruzada de k particiones](#Método-validación-cruzada-de-k-particiones)\n",
    "- [Método Leave-One-Out](#Método-Leave-One-Out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6afe50b1d8308592b2c7d80c54bdb101",
     "grade": false,
     "grade_id": "cell-e30c1d2b0de9e5bc",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Importamos todas las librerías que vamos a utilizar durante la práctica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1f8ba23b3abe07fb993e2657871b2535",
     "grade": false,
     "grade_id": "cell-703d361146ac2cb3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# %load ../../standard_import.txt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from test_helper import Test\n",
    "\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 150)\n",
    "pd.set_option('display.max_seq_items', None)\n",
    " \n",
    "#%config InlineBackend.figure_formats = {'pdf',}\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bce8320a169ac352d1a607b68ee79650",
     "grade": false,
     "grade_id": "cell-8ab970703e2e4e41",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "La librería scikit-learn nos ofrece muchas funcionalidades para realizar procesos de aprendizaje automático. En esta práctica vamos a utilizar las funciones que realizan métodos de validación de modelos. Es decir, metodologías que validen la calidad de los modelos y que por tanto, se pueden aplicar para seleccionar el mejor modelo (o los mejores valores de los híper-parámetros de un clasificador) para resolver un problema dado. Todas estas funciones están dentro de la librería [*model_selection*](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection). Para ilustrar el funcionamiento de dichas metodologías, utilizaremos el clasificador de los k vecinos más cercanos.\n",
    "\n",
    "Para desarrollar la práctica vamos a trabajar con el dataset [*Ionosphere*](https://archive.ics.uci.edu/ml/datasets/Ionosphere). Este dataset contiene la información de un problema en el que un sistema de radar recoge información de 16 antenas con el objetivo de ver si los electrones presentan algún tipo de estructura en la ionosfera (Bueno) o no (Malo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "976f9244f52de531d6a07f637df2ef0f",
     "grade": false,
     "grade_id": "cell-a65c8776a5c2a7e4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "En el siguiente código se deben leer los datos del problema Ionosphere almacenados en un archivo *ionosphere.csv*. En este caso la variable de salida es la llamada Class.\n",
    "\n",
    "Realiza la lectura de los datos almacenados en el fichero *ionosphere.csv* y guarda el resultado en una variable llamada ion. A partir de la variable ion, generad las variables X (información de entrada) e y (información de salida). Para eliminar variables (o instancias) de un DataFrame se puede utilizar el método [*drop*](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html) de Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f17c7743c7c1f933d560eacd9831ee16",
     "grade": false,
     "grade_id": "cell-9351b4b3d3b92c3a",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Se realiza la lectura del dataset sonar utilizando pandas\n",
    "    # La primera línea contiene los nombres de las variables\n",
    "    # header=None se utilizaría en caso de que no existiera una primera línea con los nombres para las variables\n",
    "\n",
    "ion = pd.read_csv('ionosphere.csv')\n",
    "\n",
    "# nombreAtSalida = <RELLENAR>\n",
    "\n",
    "# Generamos los datos de entrada y de salida: nos quedamos con las columnas correspondientes en cada caso\n",
    "X = ion.loc[:, ion.columns != 'Class'].copy()\n",
    "y = ion.loc[:,'Class'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c48591908711ccb7f6575dbe92338c9e",
     "grade": false,
     "grade_id": "cell-347ed2cbf584062c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Método Hold-out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "31f37e4ab72191826c132de483e5d318",
     "grade": false,
     "grade_id": "cell-33423ca7e5cd88b3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "El método de validación hold-out crea un conjunto de ejemplos de entrenamiento y uno de test a partir del conjunto de datos inicial. Para ello, se determina el porcentaje de ejemplos a utilizar como conjunto de entrenamiento. Estos ejemplos serán escogidos aleatoriamente. El resto de ejemplos (no asignados al conjunto de entrenamiento) serán asignados al conjuntos de test.\n",
    "\n",
    "Como hemos dicho anteriormente, en la librería *model_selection* de Scikit-learn podemos encontrar una función que realiza este proceso. Por tanto, en primer lugar, para poder utilizarla se debe importar dicha librería de este modo\n",
    "\n",
    "    from sklearn import model_selection\n",
    "\n",
    "Dentro de esta librería se encuentra la función llamada [*train_test_split*](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split) que nos realiza el proceso de división de los datos aplicando la técnica Hold-out. La función recibe varias variables de entrada y devuelve varias de salida, la llamada a dicha función es la siguiente:\n",
    "\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(inputData, outputData, train_size=porcentajeTrain, stratify=variableEstratificacion, random_state=semilla)\n",
    "\n",
    "* Los parámetros de entrada son:\n",
    "    * inputData: los datos de entrada\n",
    "    * outputData: los datos de salida\n",
    "    * porcentajeTrain: la proporción de ejemplos de entrenamiento\n",
    "    * semilla: valor de la semilla para poder generar los mismos números aleatorios y poder reproducir los resultados.\n",
    "    * variableEstratificacion: variable a utilizar para realizar el proceso de estatificación.\n",
    "* Los parámetros de salida son:\n",
    "    * X_train: los datos de entrada del conjunto de entrenamiento\n",
    "    * X_test: los datos de entrada del conjunto de test\n",
    "    * y_train: los datos de salida del conjunto de entrenamiento\n",
    "    * y_test: los datos de salida del conjunto de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "65e087b73c02d40035c4106bcd1685f6",
     "grade": false,
     "grade_id": "cell-7a76aeb1cdef1d47",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Ejercicio: utilizar el método de validación hold-out para obtener el accuracy de entrenamiento y de test con el dataset Ionosphere y utilizando KNN con la configuración por defecto vista en la práctica anterior. Utilizad el 80% de los ejemplos para el conjunto de entrenamiento y el resto para el conjunto de test. Utilizar como semilla el número 12 y recordad utilizar la estratificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b3309489230a79dd54ade2c489fed02",
     "grade": false,
     "grade_id": "cell-9343ef4f6df3bb27",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Se importan las 3 librerías necesarias para resolver el ejercicio\n",
    "from sklearn import metrics, model_selection, neighbors\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, \n",
    "                                train_size=0.8,stratify=y, random_state=123)\n",
    "\n",
    "# Entrenamiento de KNN con los valores por defecto de los híper-parámetros\n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Se obtiene el rendimiento en train y test\n",
    "y_pred_train = knn.predict(X_train)\n",
    "y_pred_test = knn.predict(X_test)\n",
    "\n",
    "accTrain = metrics.accuracy_score(y_train,y_pred_train)*100\n",
    "accTest = metrics.accuracy_score(y_test,y_pred_test)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e75e81b747b2f9196f52c947ddbdbd8",
     "grade": true,
     "grade_id": "cell-b60134a315bef73c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# ESTA CELDA DARÁ ERROR SI EL RESULTADO NO ES CORRECTO\n",
    "    # EN CASO CONTRARIO NO TENDRÁ SALIDA\n",
    "Test.assertEquals(round(accTrain, 2), 86.43, 'Valor de accuracy en train incorrecto')\n",
    "Test.assertEquals(round(accTest, 2), 83.10, 'Valor de accuracy en test incorrecto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e9b481dc7e6831be5054743003959c94",
     "grade": false,
     "grade_id": "cell-1294cab6f9bcaed5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Una vez que tenemos los conjuntos de entrenamiento y de test, podemos seleccionar los mejores valores del o híper-parámetros del algoritmo KNN (o del que estemos utilizando) aplicando esta metodología. Para ello, se deben devidir los datos de entrenamiento en otros dos conjuntos: el de entrenamiento y el de validación. Una vez que los tenemos, el conjunto de entrenamiento será utilizado para realizar el aprendizaje del clasificador con una configuración dada y cuyo rendimiento será evaluado con los ejemplos del conjunto de validación. La mejor configuración del clasificador será aquella que obtenga el mejor rendimiento con el conjunto de validación.\n",
    "\n",
    "Para evitar realizar este proceso de forma *manual*, Scikit-learn ofrece una clase que nos ayuda a realizar dicho proceso. Esta clase también está dentro del paquete **model_selection** y se llama [*GridSearchCV*](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). Su llamada y sus parámetros principales son los siguientes:\n",
    "\n",
    "    clasificadores = model_selection.GridSearchCV(clasificador, param_grid, scoring=tipoRendimiento, cv=metodoValidacion, return_train_score=devolverResultadosTrain, n_jobs=numeroTareasParalelo, verbose=informacionMostrar)\n",
    "\n",
    "* clasificador: es el clasificador del que deseamos conocer su mejor configuración. Es decir, la variable en la que almacenamos la llamada en la que definimos el clasificador (sin híper-parámetros de entrada o con los que deseemos fijar).\n",
    "* param_grid: es un diccionario cuyas claves son los nombres de los híper-parámetros a determinar su mejor configuración. Para cada clave su valor es una lista con los valores que se desean probar para dicho híper-parámetro. Por ejemplo, para el clasificador que vamos a \"optimizar\" podría ser:\n",
    "    * KNN: {'n_neighbors': [1, 3, 5, 7, 9], 'weights': ['uniform', 'distance'], 'p': [1, 2, 1.5, 3]}\n",
    "* tipoRendimiento: determina el tipo de medida a utilizar para evaluar la calidad del clasificador. Si no se especifica se utiliza la que aplica el clasificador a optimizar (normalmente todos utilizar el accuracy). Los posibles valores de este parámetro son:\n",
    "    * ’accuracy’: accuracy rate\n",
    "    * ‘precision’: precisión\n",
    "    * ‘recall’: recall o true positive rate\n",
    "    * ‘roc_auc’: área bajo la curva ROC\n",
    "    * Se podrían utilizar otras métricas de rendimiento mediante el uso de [*make_scorer*](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html).\n",
    "* metodoValidacion: modelo de validación cruzada a utilizar:\n",
    "    * Si es un valor entero determina el número de particiones para realizar la validación cruzada de K particiones. Por defecto su valor *None* que implica utilizar 5 como número de particiones.\n",
    "    * Un objeto de un método de validación de modelos.\n",
    "* devolverResultadosTrain: variable booleana que determina si se devuelven los resultados de entrenamiento o no. Por defecto su valor es False.\n",
    "* numeroTareasParalelo: valor entero que determina el número de tareas a realizar en paralelo. Por defecto no se utiliza paralelización. Si se le asigna -1 se utilizan todos los procesadores disponibles.\n",
    "* informacionMostrar: valor entero que determina la información a mostrar en el proceso. A mayor valor se muestra más información. Por defecto (0) no se muestra nada.\n",
    "\n",
    "El parámetro de salida es un conjunto de clasificadores (todas las posibles combinaciones de los híper-parámetros a utilizar). Al igual que hacemos con un solo clasificador, debemos entrenar todos ellos con los datos de train (llamada al método *fit* con la variable donde se almacena el conjunto de clasificadores). En este caso, la llamada al entrenamiento ya realiza internamente tanto el entrenamiento como la evaluación del rendimiento de los clasificadores en el conjunto de validación. Por este motivo, tras entrenarlos (llamada a *fit*), ya se ha calculado internamente la mejor configuración. La mejor configuración está almacenada en el campo *best_params_* y su rendimiento asociado está almacenado en el campo *best_score_*. Podemos visualizarlos con *print*:\n",
    "\n",
    "    print(clasificadores.best_params_)\n",
    "    print(clasificadores.best_score_)\n",
    "\n",
    "Además, por defecto (refit es True) se entrena un clasificador con la mejor configuración encontrada que permite utilizar directamente el método *predict* sobre la instancia de *GridSearchCV* (usando dicho clasificador). Este clasificador también lo tenemos disponible mediante el atributo \n",
    "\n",
    "    clasificadores.best_estimator_\n",
    "    \n",
    "Para comprobar que efectivamente la configuración mostrada es la mejor, podemos visualizar los resultados de todos los clasificadores considerados (todas las combinaciones de híper-parámetros posibles). Para que el siguiente código funcione debéis especificar que se devuelvan los resultados de entrenamiento en el constructor. Para ello se debe utilizar el siguiente código:\n",
    "\n",
    "    resultadosMostrar = zip(clasificadores.cv_results_['params'],clasificadores.cv_results_['mean_test_score'],clasificadores.cv_results_['mean_train_score'])\n",
    "    for params, mean_test_score, mean_train_score in resultadosMostrar:\n",
    "        print(\"%0.3f (Train: %0.3f) for %r\" % (mean_test_score, mean_train_score, params))\n",
    "        print()\n",
    "\n",
    "Se puede observar que en la variable *resultadosMostrar* estamos utilizando el atributo *cv_results_* (es un DataFrame de Pandas) y seleccionando algunas de sus columnas para mostrar (podríamos incluir más información)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9dd537104877f17093985738ffbec081",
     "grade": false,
     "grade_id": "cell-fb180defa4cd6d77",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "En este caso, vamos a aplicar Hold-out como metodología de selección de modelos. Para ello, se puede utilizar el método [*StratifiedShuffleSplit*](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html) como método de validación dentro de *GridSearchCV* ya que permite que haga una división de ejemplos en entrenamiento y validación utilizando la estratificación. Para ello, se le debe especificar que haga una sola división de los ejemplos (*n_splits*) y que utilice el 20% de los mismos como conjunto de validación (*test_size*).\n",
    "\n",
    "Ejercicio: determina la mejor configuración de KNN utilizando los valores de los híper-parámetros mostrados en el texto anterior utilizando Hold-out. Una vez se haya obtenido la mejor configuración, se debe obtener el rendimiento de la misma tanto con los ejemplos de entrenamiento como con los de test obtenidos previamente.\n",
    "\n",
    "NOTA: Los ejemplos asignados a cada partición dentro de *GridSearchCV* se escogen al azar por lo que de ejecución a ejecución los resultados pueden variar. Para evitar este comportamiento podemos determinar la semilla a utilizar a la hora de generar los números aleatorios. La semilla será un número entero que implica que el número aleatorio generado es siempre el mismo. Por tanto, los ejemplos irán siempre a la misma partición y los resultados serán siempre los mismo. Para fijar la semilla de Numpy, que es la utilizada, se utiliza la siguiente instrucción:\n",
    "\n",
    "    np.random.seed(valorEntero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "933dcaaf192896e71d161cac83b3bd76",
     "grade": false,
     "grade_id": "cell-0e30307220b48a27",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 1, 'p': 1, 'weights': 'uniform'}\n",
      "0.9464285714285714\n",
      "0.9464\n"
     ]
    }
   ],
   "source": [
    "# Se fija la semilla de numpy para que la generación aleatoria siempre nos de los mismos números\n",
    "np.random.seed(seed=12)\n",
    "# Realizamos el proceso para KNN por lo que hay que llamar al constructor de dicho clasificador\n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "# Se define el grid de parámetros a utilizar\n",
    "    # Estos parámetros nos darán todas las posibles configuraciones del clasificador KNN\n",
    "        # Cada combinación de parámetros es una configuración diferente\n",
    "param_grid = {'n_neighbors': [1, 3, 5, 7, 9], 'weights': ['uniform', 'distance'], 'p': [1, 2, 1.5, 3]}\n",
    "\n",
    "# Llamada la función GridSearchCV que nos crea todas las cominaciones del grid anterior\n",
    "sss = model_selection.StratifiedShuffleSplit(n_splits=1, test_size=0.2)\n",
    "\n",
    "clasificadores_ho = model_selection.GridSearchCV(knn, param_grid, scoring='accuracy',cv=sss)\n",
    "\n",
    "# Entrenamiento de todos los clasificadores con todos los datos de entrenamiento\n",
    "clasificadores_ho.fit(X_train,y_train)\n",
    "# Se muestra la mejor configuración y su accuracy asociado\n",
    "print(clasificadores_ho.best_params_)\n",
    "print(clasificadores_ho.best_score_)\n",
    "\n",
    "# Almacenamos el DataFrame con los resultados\n",
    "diccionarioResultados_ho = clasificadores_ho.cv_results_\n",
    "# Se muestra el accuracy obtenido para cada posible combinación de parámetros\n",
    "\n",
    "print(round(np.max(diccionarioResultados_ho['mean_test_score']), 4))\n",
    "\n",
    "# Se obtiene el rendimiento en entrenamiento y test por la mejor configuración\n",
    "y_pred_train = clasificadores_ho.predict(X_train)\n",
    "y_pred_test = clasificadores_ho.predict(X_test)\n",
    "\n",
    "accTrain_ho = metrics.accuracy_score(y_train,y_pred_train)*100\n",
    "accTest_ho = metrics.accuracy_score(y_test,y_pred_test)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e150c69020b79e8f54ab6bfe52bdc47f",
     "grade": true,
     "grade_id": "cell-011b3d88c0651062",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# ESTA CELDA DARÁ ERROR SI EL RESULTADO NO ES CORRECTO\n",
    "    # EN CASO CONTRARIO NO TENDRÁ SALIDA\n",
    "Test.assertEquals(round(accTrain_ho, 2), 100.00, 'Valor de accuracy en train incorrecto')\n",
    "Test.assertEquals(round(accTest_ho, 2), 90.14, 'Valor de accuracy en test incorrecto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "75d1cb7b975fac6678112308e568ec61",
     "grade": true,
     "grade_id": "cell-d0fa6cd15b04eda6",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# ESTA CELDA DARÁ ERROR SI EL RESULTADO NO ES CORRECTO\n",
    "    # EN CASO CONTRARIO NO TENDRÁ SALIDA\n",
    "indice = np.argmax(diccionarioResultados_ho['mean_test_score'])\n",
    "Test.assertEquals(round(np.max(diccionarioResultados_ho['mean_test_score']), 4), 0.9464, \"Accuracy de la mejor configuración incorrecto\")\n",
    "Test.assertEquals(diccionarioResultados_ho['params'][indice], {'n_neighbors': 1, 'weights': 'uniform', 'p': 1}, \"Mejor configuración incorrecta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "36fdd818d0e9228b5e78a628b79cf6cb",
     "grade": false,
     "grade_id": "cell-e8975a50c2107c27",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Método validación cruzada de k particiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0b8c798b1738f985344bbd53a7a43fe6",
     "grade": false,
     "grade_id": "cell-c945541297535884",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "El método de validación cruzada de k particiones, divide el conjunto de ejemplos original en k particiones manteniendo la distribución de las clases. Posteriormente, para realizar el aprendizaje se fusionan 4 de estas particiones para formar el conjunto de entrenamiento y la partición restante se utiliza como conjunto de test. Este proceso se realiza k veces utilizando una partición diferente como conjunto de test cada vez. En Scikit-learn, existe una función llamada [*StratifiedKFold*](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold) (también en la librería *model_selection*) que realiza la división del conjunto de ejemplos original en particiones y forma los k conjuntos de entrenamiento y de test. La llamada al constuctor y sus principales parámetros de entrada son:\n",
    "\n",
    "    validacionCruzada = model_selection.StratifiedKFold(n_splits=numeroParticiones, random_state=semilla)\n",
    "\n",
    "Los parámetros de entrada son:\n",
    "* numeroParticiones: valor entero que determina el número de particiones a generar. Por defecto es 3.\n",
    "* semilla: valor que determina la semilla para la generación de números aleatorios.\n",
    "\n",
    "Si se quisiera realizar la validación de modelos de forma *manual*, para generar los iteradores de índices se debería ejecutar el método *split* utilizando el objeto generado por el constructor (variable validacionCruzada). Al método split se le deben pasar tanto los datos se entrada como los de salida.\n",
    "\n",
    "    iteradorIndices = validacionCruzada.split(X, y)\n",
    "    \n",
    "Una vez realizada esta instrucción se puede realizar el bucle para realizar las k iteraciones:\n",
    "  \n",
    "    for train_index, val_index in iteradorIndices:\n",
    "\n",
    "De esta forma el bucle for se realizará K veces y en cada iteración tendremos:\n",
    "\n",
    "* En la variable train_index estarán los índices de los ejemplos a utilizar como conjunto de entrenamiento. El conjunto de entrenamiento estará formado por todas las filas del campo data cuyos índices estén en train_index y todas las columnas (para las clases lo mismo). Es decir, X[train_index, :] e y[train_index].\n",
    "* En la variable val_index estarán los índices de los ejemplos a utilizar como conjunto de validación. El conjunto de validación estará formado por todas las filas del campo data cuyos índices estén en val_index y todas las columnas (para las clases lo mismo). Es decir, X[val_index, :] e y[val_index]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dd7d70e6345524d489f5ad4a8e9a63da",
     "grade": false,
     "grade_id": "cell-a96cfa576339a26a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Ejercicio: realizar el proceso de validación cruzada para el dataset Ionosphere y mostrar para cada partición (iteración del bucle for) el accuracy en train y en validación. Probar 5 y 10 como valores de K. Utilizar como clasificador KNN con la configuración por defecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2a205f8e3d12da766e645673a2f8acd8",
     "grade": false,
     "grade_id": "cell-1f43b836ab9e3ae6",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La media de las 5% particiones en train es: 87.03685815963397%\n",
      "La media de las 5% particiones en validación es: 83.77464788732395%\n",
      "La media de las 10% particiones en train es: 87.27476391400441%\n",
      "La media de las 10% particiones en validación es: 83.77777777777779%\n"
     ]
    }
   ],
   "source": [
    "# Se fija la semilla de numpy para que la generación aleatoria siempre nos de los mismos números\n",
    "np.random.seed(seed=12)\n",
    "\n",
    "# Listas para almacenar los resultados de accuracy en train y validación\n",
    "listaMediasTrain = []\n",
    "listaMediasVal = []\n",
    "# Para las dos validaciones cruzadas (de 5 y de 10 particiones)\n",
    "for k in [5, 10]:\n",
    "    # Llamada al constructor de la validación cruzada\n",
    "    validacionCruzada = model_selection.StratifiedKFold(n_splits=k,shuffle=True)\n",
    "    # Llamada a la función que nos da los iteradores con los índices de los ejemplos a utilizar en entrenamiento y en validación\n",
    "    iteradorIndices = validacionCruzada.split(X, y)\n",
    "    # Se crear las variables (arrays de numpy) para almacenar los k resultados de entrenamiento y de validación\n",
    "    train = np.zeros(k)\n",
    "    val = np.zeros(k)\n",
    "    # Variable para almacenar el índice de la partición\n",
    "    i = 0\n",
    "    for train_index, val_index in iteradorIndices:\n",
    "        # Entrenar KNN con los datos de train\n",
    "        knn = neighbors.KNeighborsClassifier()\n",
    "        knn.fit(X.values[train_index],y.values[train_index])\n",
    "        # Prededecir los datos de train y calcular el porcentaje de acierto entre 0 y 100 (almacenarlo en la posición correspondiente)\n",
    "        train_pred = knn.predict(X.values[train_index,:])\n",
    "        train[i] = metrics.accuracy_score(y.values[train_index],train_pred)*100\n",
    "        # Prededecir los datos de validación y calcular el porcentaje de acierto entre 0 y 100 (almacenarlo en la posición correspondiente) \n",
    "        val_pred = knn.predict(X.values[val_index,:])\n",
    "        val[i] = metrics.accuracy_score(y.values[val_index],val_pred)*100\n",
    "        i = i + 1\n",
    "    \n",
    "    # Cálculo y guardado de las medias de las k particiones tanto de entrenamiento como de validación\n",
    "    mediaTrain = np.mean(train)\n",
    "    listaMediasTrain.append(mediaTrain)\n",
    "    print ('La media de las {}% particiones en train es: {}%'.format(k, mediaTrain))\n",
    "    mediaVal = np.mean(val)\n",
    "    listaMediasVal.append(mediaVal)\n",
    "    print ('La media de las {}% particiones en validación es: {}%'.format(k, mediaVal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "58952ba8feb98e02053c28fda0f2a45b",
     "grade": true,
     "grade_id": "cell-e9ad30769ad0b39c",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test failed. Valores de accuracy en test incorrectos\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Valores de accuracy en test incorrectos",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-6fee7ae76718>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ESTA CELDA DARÁ ERROR SI EL RESULTADO NO ES CORRECTO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# EN CASO CONTRARIO NO TENDRÁ SALIDA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mTest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massertEquals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlistaMediasTrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m86.07\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m86.11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Valores de accuracy en test incorrectos'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mTest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massertEquals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlistaMediasVal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m83.21\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m83.57\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Valores de accuracy en validación incorrectos'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/Mineria/Practicas/Mineria-de-Datos/Practica2/test_helper.py\u001b[0m in \u001b[0;36massertEquals\u001b[0;34m(cls, var, val, msg)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0massertEquals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massertTrue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/Mineria/Practicas/Mineria-de-Datos/Practica2/test_helper.py\u001b[0m in \u001b[0;36massertTrue\u001b[0;34m(cls, result, msg)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"1 test failed. \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m       \u001b[0;31m# if cls.failFast:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# if cls.private:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Valores de accuracy en test incorrectos"
     ]
    }
   ],
   "source": [
    "# ESTA CELDA DARÁ ERROR SI EL RESULTADO NO ES CORRECTO\n",
    "    # EN CASO CONTRARIO NO TENDRÁ SALIDA\n",
    "Test.assertEquals(list(map(lambda x: round(x, 2), listaMediasTrain)), [86.07,86.11], 'Valores de accuracy en test incorrectos')\n",
    "Test.assertEquals(list(map(lambda x: round(x, 2), listaMediasVal)), [83.21,83.57], 'Valores de accuracy en validación incorrectos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e6023464d3f7c51bd68afcb6f100ff02",
     "grade": false,
     "grade_id": "cell-0bfdccb63941f2d1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "El proceso anterior (utilizando un número de particiones específico) habría que repetirlo para todas las posibles configuraciones y seleccionar la que mejor resultado obtenga en validación. Para evitar toda esta programación, al igual que hemos hecho con Hold-out, podemos utilizar la clase *GridSearchCV* especificando el número de particiones a realizar.\n",
    "\n",
    "Ejercicio: repetid el ejercicio de selección de la mejor configuración de KNN utilizando una validación cruzada de 10 particiones como método de validación de modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "90accbf0ba2a10634e23f2182b158e7f",
     "grade": false,
     "grade_id": "cell-7c087aa03d97ff09",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 1, 'p': 1, 'weights': 'uniform'}\n",
      "0.8964285714285714\n"
     ]
    }
   ],
   "source": [
    "# Se importan las librerías que vamos a utilizar en este ejercicio\n",
    "from sklearn import neighbors\n",
    "\n",
    "# Se fija la semilla de numpy para que la generación aleatoria siempre nos de los mismos números\n",
    "np.random.seed(seed=12)\n",
    "\n",
    "# Realizamos el proceso para KNN por lo que hay que llamar al constructor de dicho clasificador\n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "# Se define el grid de parámetros a utilizar\n",
    "    # Estos parámetros nos darán todas las posibles configuraciones del clasificador KNN\n",
    "        # Cada combinación de parámetros es una configuración diferente\n",
    "param_grid = {'n_neighbors': [1, 3, 5, 7, 9], 'weights': ['uniform', 'distance'], 'p': [1, 2, 1.5, 3]}\n",
    "\n",
    "# Llamada la función GridSearchCV que nos crea todas las cominaciones del grid anterior\n",
    "clasificadores_vc = model_selection.GridSearchCV(knn, param_grid, scoring='accuracy', cv=10)\n",
    "# Entrenamiento de todos los clasificadores con todos los datos de entrenamiento\n",
    "clasificadores_vc.fit(X_train,y_train)\n",
    "# Se muestra la mejor configuración y su accuracy asociado\n",
    "print (clasificadores_vc.best_params_)\n",
    "print (clasificadores_vc.best_score_)\n",
    "\n",
    "# Almacenamos el DataFrame con los resultados\n",
    "diccionarioResultados_vc = clasificadores_vc.cv_results_\n",
    "\n",
    "# Se obtiene el rendimiento en entrenamiento y test por la mejor configuración\n",
    "y_pred_train = clasificadores_vc.predict(X_train)\n",
    "y_pred_test = clasificadores_vc.predict(X_test)\n",
    "accTrain_vc = metrics.accuracy_score(y_train,y_pred_train)*100\n",
    "accTest_vc = metrics.accuracy_score(y_test,y_pred_test)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10e3f7348cca3e78cbb94a65e0825592",
     "grade": true,
     "grade_id": "cell-fc45b053379c5c9d",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# ESTA CELDA DARÁ ERROR SI EL RESULTADO NO ES CORRECTO\n",
    "    # EN CASO CONTRARIO NO TENDRÁ SALIDA\n",
    "Test.assertEquals(round(accTrain_vc, 2), 100.00, 'Valor de accuracy en train incorrecto')\n",
    "Test.assertEquals(round(accTest_vc, 2), 90.14, 'Valor de accuracy en test incorrecto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5e001e27ad2c26b6a68fc4691335c2a5",
     "grade": true,
     "grade_id": "cell-176d098fa2a38ac9",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# ESTA CELDA DARÁ ERROR SI EL RESULTADO NO ES CORRECTO\n",
    "    # EN CASO CONTRARIO NO TENDRÁ SALIDA\n",
    "indice = np.argmax(diccionarioResultados_vc['mean_test_score'])\n",
    "Test.assertEquals(round(np.max(diccionarioResultados_vc['mean_test_score']), 4), 0.8964, \"Accuracy de la mejor configuración incorrecto\")\n",
    "Test.assertEquals(diccionarioResultados_vc['params'][indice], {'n_neighbors': 1, 'weights': 'uniform', 'p': 1}, \"Mejor configuración incorrecta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "07c404916bdb622e5372e2edba864e56",
     "grade": false,
     "grade_id": "cell-1c77391dcf3b0804",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Método Leave-One-Out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bc0ff3e3028fe2ba59827a57f5505e3d",
     "grade": false,
     "grade_id": "cell-4056f3d1e1f5af43",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "El tercer método de validación es el leave-one-out. Es como el método de validación cruzada de k particiones cuando k es igual al número de ejemplos del dataset. La función de scikit-learn que realiza este proceso es [*LeaveOneOut*](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneOut.html#sklearn.model_selection.LeaveOneOut). Su llamada y su uso es el siguiente:\n",
    "\n",
    "    loo = model_selection.LeaveOneOut()\n",
    "    \n",
    "Al igual que para la validación cruzada, para generar los iteradores de índices, se debe ejecutar el método *split* utilizando el objeto generado por el constructor (variable loo). En este caso, solamente es necesario pasar como parámetro de entrada los valores de entrada de los ejemplos (X).\n",
    "\n",
    "    iteradorIndices = loo.split(X)\n",
    "    \n",
    "Una vez realizada esta instrucción se puede realizar el bucle para realizar las k iteraciones del mismo modo que anteriormente. La diferencia es que en cada iteración, en la variable *val_index* solo habrá un índice puesto que se usa un solo ejemplo para evaluar el modelo aprendido. Por tanto, para obtener el resultado en validación se debe almacenar, en cada iteración del bucle for, la predicción del ejemplo de validación (en un vector de tantos elementos como ejemplos del dataset) y al finalizar el bucle for se debe comparar este vector con las clases reales del problema para obtener el accuracy rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "86e1d49ed5c50faafd8e9227e63e69ce",
     "grade": false,
     "grade_id": "cell-37733bea617a6ef4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Ejercicio: realizar el método de validación leave-one-out con el dataset Ionosphere utilizando KNN con la configuración por defecto y mostrar el accuracy obtenido en validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e76ac4bf34f756b5c6fce810c1d3e0d1",
     "grade": false,
     "grade_id": "cell-c7302eeca982aa7e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El accuracy en validación es: 84.62%\n"
     ]
    }
   ],
   "source": [
    "# Se fija la semilla de numpy para que la generación aleatoria siempre nos de los mismos números\n",
    "np.random.seed(seed=12)\n",
    "\n",
    "# Llamada al constructor del proceso leave one out\n",
    "loo = model_selection.LeaveOneOut()\n",
    "# Llamada a la función que nos da los iteradores con los índices de los ejemplos a utilizar en entrenamiento y en test\n",
    "iteradorIndices = loo.split(X)\n",
    "\n",
    "salida = []\n",
    "# Para cada partición de ejemplos\n",
    "for train_index,val_index in iteradorIndices:\n",
    "    # Entrenar KNN con los datos de train\n",
    "    knn = neighbors.KNeighborsClassifier()\n",
    "    knn.fit(X.values[train_index,:],y.values[train_index])\n",
    "    # Predecir la clase del ejemplo de validación y añadirla a la lista\n",
    "    salida.append(knn.predict(X.values[val_index,:]))\n",
    "\n",
    "# Cálculo del accuracy de las predicciones realizadas en validación (entre 0.0 y 100.0)\n",
    "accVal = metrics.accuracy_score(y.values,salida)*100\n",
    "print('El accuracy en validación es: {:.2f}%'.format(accVal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1b578746b2911cce6b9bf2897144557f",
     "grade": true,
     "grade_id": "cell-3fefad88e53ac967",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test failed. Accuracy incorrecto\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Accuracy incorrecto",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-d61da491a88f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ESTA CELDA DARÁ ERROR SI EL RESULTADO NO ES CORRECTO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# EN CASO CONTRARIO NO TENDRÁ SALIDA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mTest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massertEquals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccVal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m83.57\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Accuracy incorrecto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documentos/Mineria/Practicas/Mineria-de-Datos/Practica2/test_helper.py\u001b[0m in \u001b[0;36massertEquals\u001b[0;34m(cls, var, val, msg)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0massertEquals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massertTrue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/Mineria/Practicas/Mineria-de-Datos/Practica2/test_helper.py\u001b[0m in \u001b[0;36massertTrue\u001b[0;34m(cls, result, msg)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"1 test failed. \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m       \u001b[0;31m# if cls.failFast:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# if cls.private:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Accuracy incorrecto"
     ]
    }
   ],
   "source": [
    "# ESTA CELDA DARÁ ERROR SI EL RESULTADO NO ES CORRECTO\n",
    "    # EN CASO CONTRARIO NO TENDRÁ SALIDA\n",
    "Test.assertEquals(round(accVal, 2), 83.57, 'Accuracy incorrecto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d857fd7732f76ef6b6702e5c945c577e",
     "grade": false,
     "grade_id": "cell-750de4c828062d1b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Ejercicio: repetid el ejercicio de selección de la mejor configuración de KNN utilizando leave-one-out como método de validación de modelos.\n",
    "\n",
    "NOTA: esta celda puede tardar varios minutos en ejecutarse. Se recomienda usar todos los cores del ordenador (n_jobs=-1 en GridSearchCV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "84b936cb5fc05c67bcb0a734477ed1f5",
     "grade": false,
     "grade_id": "cell-dfe2d0ecfb9adb93",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 1, 'p': 1, 'weights': 'uniform'}\n",
      "0.9035714285714285\n",
      "<bound method BaseSearchCV.score of GridSearchCV(cv=None, error_score=nan,\n",
      "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
      "                                            metric='minkowski',\n",
      "                                            metric_params=None, n_jobs=None,\n",
      "                                            n_neighbors=5, p=2,\n",
      "                                            weights='uniform'),\n",
      "             iid='deprecated', n_jobs=None,\n",
      "             param_grid={'n_neighbors': [1, 3, 5, 7, 9], 'p': [1, 2, 1.5, 3],\n",
      "                         'weights': ['uniform', 'distance']},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring='accuracy', verbose=0)>\n"
     ]
    }
   ],
   "source": [
    "# Se fija la semilla de numpy para que la generación aleatoria siempre nos de los mismos números\n",
    "np.random.seed(seed=12)\n",
    "\n",
    "# Realizamos el proceso para KNN por lo que hay que llamar al constructor de dicho clasificador\n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "# Se define el grid de parámetros a utilizar\n",
    "    # Estos parámetros nos darán todas las posibles configuraciones del clasificador KNN\n",
    "        # Cada combinación de parámetros es una configuración diferente\n",
    "param_grid = {'n_neighbors': [1, 3, 5, 7, 9], 'weights': ['uniform', 'distance'], 'p': [1, 2, 1.5, 3]}\n",
    "\n",
    "# Llamada la función GridSearchCV que nos crea todas las cominaciones del grid anterior\n",
    "clasificadores_loo = model_selection.GridSearchCV(knn, param_grid, scoring='accuracy')\n",
    "# Entrenamiento de todos los clasificadores con todos los ejemplos de entrenamiento\n",
    "clasificadores_loo.fit(X_train.values,y_train.values)\n",
    "# Se muestra la mejor configuración y su accuracy asociado\n",
    "print (clasificadores_loo.best_params_)\n",
    "print (clasificadores_loo.best_score_)\n",
    "# Almacenamos el DataFrame con los resultados\n",
    "diccionarioResultados_loo = clasificadores_loo.cv_results_\n",
    "# Se muestra el accuracy obtenido para cada posible combinación de parámetros\n",
    "print(clasificadores_loo.score)\n",
    "# Se obtiene el rendimiento en entrenamiento y test por la mejor configuración\n",
    "y_pred_train = clasificadores_loo.predict(X_train)\n",
    "y_pred_test = clasificadores_loo.predict(X_test)\n",
    "\n",
    "accTrain_loo =  metrics.accuracy_score(y_train,y_pred_train)*100\n",
    "accTest_loo = metrics.accuracy_score(y_test,y_pred_test)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1ab69a48331e25825491ca0879b0339c",
     "grade": true,
     "grade_id": "cell-107f95ae634de18a",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# ESTA CELDA DARÁ ERROR SI EL RESULTADO NO ES CORRECTO\n",
    "    # EN CASO CONTRARIO NO TENDRÁ SALIDA\n",
    "Test.assertEquals(round(accTrain_loo, 2), 100.00, 'Valor de accuracy en train incorrecto')\n",
    "Test.assertEquals(round(accTest_loo, 2), 90.14, 'Valor de accuracy en test incorrecto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3642c19eb1189b7832eda9ba7fe6f513",
     "grade": true,
     "grade_id": "cell-c0d65a89eeab7c9c",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test failed. Accuracy de la mejor configuración incorrecto\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Accuracy de la mejor configuración incorrecto",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-bb37d53dcab1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# EN CASO CONTRARIO NO TENDRÁ SALIDA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mindice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiccionarioResultados_loo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mTest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massertEquals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiccionarioResultados_loo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Accuracy de la mejor configuración incorrecto\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mTest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massertEquals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiccionarioResultados_loo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'n_neighbors'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'weights'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'uniform'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'p'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Mejor configuración incorrecta\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/Mineria/Practicas/Mineria-de-Datos/Practica2/test_helper.py\u001b[0m in \u001b[0;36massertEquals\u001b[0;34m(cls, var, val, msg)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0massertEquals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massertTrue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/Mineria/Practicas/Mineria-de-Datos/Practica2/test_helper.py\u001b[0m in \u001b[0;36massertTrue\u001b[0;34m(cls, result, msg)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"1 test failed. \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m       \u001b[0;31m# if cls.failFast:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# if cls.private:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Accuracy de la mejor configuración incorrecto"
     ]
    }
   ],
   "source": [
    "# ESTA CELDA DARÁ ERROR SI EL RESULTADO NO ES CORRECTO\n",
    "    # EN CASO CONTRARIO NO TENDRÁ SALIDA\n",
    "indice = np.argmax(diccionarioResultados_loo['mean_test_score'])\n",
    "Test.assertEquals(round(np.max(diccionarioResultados_loo['mean_test_score']),4), 0.9, \"Accuracy de la mejor configuración incorrecto\")\n",
    "Test.assertEquals(diccionarioResultados_loo['params'][indice], {'n_neighbors': 1, 'weights': 'uniform', 'p': 1}, \"Mejor configuración incorrecta\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37machlearn] *",
   "language": "python",
   "name": "conda-env-py37machlearn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
